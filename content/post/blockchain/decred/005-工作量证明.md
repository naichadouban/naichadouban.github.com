---
title: 工作量证明
date: 2019-06-16T01:00:00+08:00
tags: ["decred"]
categories: ["decred"]
draft: false

---

# 5. 工作量证明
## PoW举例
找到一个语句，使之哈希值的十六进制表示以0开头。幸运的是，这很容易！在例10-10中语句 "I am Satoshi Nakamoto13" 的哈希值是 0ebc56d59a34f5082aaef3d66b37a661696c2b618e62432727216ba9531041a5 ，刚好满足条件。我们得到它用了13次。用概率的角度 来看，如果哈希函数的输出是平均分布的，我们可以期望每16次得到一个以0开头的哈希值（十六进制个位数字为0到 F）。从数字的角度来看，我们要找的是小于 0x1000000000000000000000000000000000000000000000000000000000000000 的哈希值。
我们称这个为Target目标阈值，我们的目的是找到一个小于这个目标的哈希值。如果我们减小这个目标值，那找到一个小于它的哈希值会越来越难。因为前面的0越来越多, 那么计算的次数就越来越多, 如果前面有8个0, 那么按概率来算, 要计算16^8次:
0x0000000010000000000000
这个目标值就是难度, 目标值越小, 难度越大

## 难度值表示
DCR和BTC类似
```
$ bitcoin-cli get blockhash 277316
0000000000000001b6b9a13b095e96db41c4a928b97ef2d944a9b31b2cc7bdc4

$ bitcoin-cli getblock 0000000000000001b6b9a13b095e96db41c4a928b97ef2d9&#92;44a9b31b2cc7bdc4
{
"hash" : "0000000000000001b6b9a13b095e96db41c4a928b97ef2d944a9b31b2cc7bdc4", // 15个0
"confirmations" : 35561,
"size" : 218629,
"height" : 277316,
"version" : 2,
"merkleroot" : "c91c008c26e50763e9f548bb8b2fc323735f73577effbc55502c51eb4cc7cf2e",
"tx" : [
  "d5ada064c6417ca25c4308bd158c34b77e1c0eca2a73cda16c737e7424afba2f",
  "b268b45c59b39d759614757718b9918caf0ba9d97c56f3b91956ff877c503fbe",
  ... 417 more transactions ...//这一行显示交易数量
 ],
"time" : 1388185914,
"nonce" : 924591752,
"bits" : "1903a30c", // 难度值
"difficulty" : 1180923195.25802612,
"chainwork" : "000000000000000000000000000000000000000000000934695e92aaf53afa1a",
"previousblockhash" : "0000000000000002a7bbd25a417c0374cc55261021e8a9ca74442b01284f0569"
}

```
我们在区块中看到难度目标，其被标为"难度位"或简称"bits"。在区块277,316中，它的值为 0x1903a30c。 这个标记的值被存为幂/系数格式，前两位十六进制数字为幂（exponent），接下来得六位为系数（coefficient）。在这个区块里，0x19为幂，而 0x03a30c为系数。
计算难度目标的公式为:
```
target = coefficient  2^(8  (exponent – 3))

```
由此公式及难度的值 0x1903a30c，可得：
```
target = 0x03a30c  2^(0x08  (0x19 - 0x03))
=> target = 0x03a30c  2^(0x08  0x16)
=> target = 0x03a30c  2^0xB0

```
按十进制计算为：
```
=> target = 238,348  2^176
=> target = 22,829,202,948,393,929,850,749,706,076,701,368,331,072,452,018,388,575,715,328

```
转化为十六进制后为：(15个0)
```
=> target = 0x0000000000000003A30C00000000000000000000000000000000000000000000

```
也就是说高度为277,316的有效区块的头信息哈希值是小于这个目标值的。这个数字的二进制表示中前60位都是0。在 这个难度上，一个每秒可以处理1万亿个哈希计算的矿工（1 tera-hash per second 或 1 TH/sec）平均每8,496个区块才能找到一个正确结果，换句话说，平均每59天，才能为某一个区块找到正确的哈希值。
## checkProofOfWork() 难度检查
BlockHeader有以下字段:
```
// block (MsgBlock) and headers (MsgHeaders) messages.
type BlockHeader struct {
   // Difficulty target for the block.
   Bits uint32 // 难度值
   // Nonce used to generate the block.
   Nonce uint32
}

```
checkBlockHeaderSanity() 调用了 checkProofOfWork()进行了工作量证明的验证:
```
// /blockchain/validate.go 
func checkProofOfWork(header wire.BlockHeader, powLimit big.Int, flags BehaviorFlags) error {
   // (1) The target difficulty must be larger than zero.
   target := CompactToBig(header.Bits)
   // (2)
   if target.Sign() <= 0 {
      str := fmt.Sprintf("block target difficulty of %064x is too "+
         "low", target)
      return ruleError(ErrUnexpectedDifficulty, str)
   }
   // (3)
   // The target difficulty must be less than the maximum allowed.
   if target.Cmp(powLimit) > 0 {
      str := fmt.Sprintf("block target difficulty of %064x is "+
         "higher than max of %064x", target, powLimit)
      return ruleError(ErrUnexpectedDifficulty, str)
   }

   // The block hash must be less than the claimed target unless the flag
   // to avoid proof of work checks is set.
   if flags&amp;BFNoPoWCheck != BFNoPoWCheck {
      // (4) The block hash must be less than the claimed target.
      hash := header.BlockHash()
      hashNum := HashToBig(&amp;hash)
      if hashNum.Cmp(target) > 0 {
         str := fmt.Sprintf("block hash of %064x is higher than"+
            " expected max of %064x", hashNum, target)
         return ruleError(ErrHighHash, str)
      }
   }

   return nil
}

```
其主要步骤是:

 调用CompactToBig()方法，将区块头中区块目标难度Bits转换成整数值，便于后续进行数值比较;
 代码(2)和(3)处检测难度值是否在(0, 2^224-1)范围内;
 随后，调用HashToBig()将区块头Hash转换成整数值，并与目标难度值进行比较，如代码(4)处所示，如果区块头Hash值大于目标难度值，则表明该区块不满足工作量证明;

区块头中目标难度的编码方式如下:
```
//  -------------------------------------------------
// |   Exponent     |    Sign    |    Mantissa     |
// -------------------------------------------------
// | 8 bits [31-24] | 1 bit [23] | 23 bits [22-00] |
// -------------------------------------------------

```
对应的计算公式是:
![image.png](https://upload-images.jianshu.io/upload_images/422094-058064f37064343c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中，sign指符号位对应的值(0或1, 如果是1difficulty就是负数, 是不允许的)，mantissa表示尾数，exponent表示指数。CompactToBig()就是根据上述编码规则和公式来计算难度值的；相应地，BigToCompact()将难度值按上述编码规则转换成32位bit序列，相关的代码读者可以自行分析。256位Hash值是按小端字节序，在HashToBig()中转换成big.Int值时，作了字节序转换。
## calcNextRequiredDifficulty() 难度调整
### BTC
calcNextRequiredDifficulty()涉及到难度调整算法, 我们先看看看Bitcoin难度调整的实现:
```
//btcd/blockchain/difficulty.go
func (b BlockChain) calcNextRequiredDifficulty(lastNode blockNode, newBlockTime time.Time) (uint32, error) {
    // Genesis block.
    if lastNode == nil {
        return b.chainParams.PowLimitBits, nil
    }

    // Return the previous block's difficulty requirements if this block
    // is not at a difficulty retarget interval.
    if (lastNode.height+1)%b.blocksPerRetarget != 0 {                         (1)
        // For networks that support it, allow special reduction of the
        // required difficulty once too much time has elapsed without
        // mining a block.
        if b.chainParams.ReduceMinDifficulty {
            ......
        }

        // For the main network (or any unrecognized networks), simply
        // return the previous block's difficulty requirements.
        return lastNode.bits, nil                                             (2)
    }

    // Get the block node at the previous retarget (targetTimespan days
    // worth of blocks).
    firstNode := lastNode
    for i := int32(0); i < b.blocksPerRetarget-1 &amp;&amp; firstNode != nil; i++ {
        // Get the previous block node.  This function is used over
        // simply accessing firstNode.parent directly as it will
        // dynamically create previous block nodes as needed.  This
        // helps allow only the pieces of the chain that are needed
        // to remain in memory.
        var err error
        firstNode, err = b.index.PrevNodeFromNode(firstNode)                  (3)
        if err != nil {
            return 0, err
        }
    }

    if firstNode == nil {
        return 0, AssertError("unable to obtain previous retarget block")
    }

    // Limit the amount of adjustment that can occur to the previous
    // difficulty.
    actualTimespan := lastNode.timestamp - firstNode.timestamp
    adjustedTimespan := actualTimespan                                        (4)
    if actualTimespan < b.minRetargetTimespan {
        adjustedTimespan = b.minRetargetTimespan
    } else if actualTimespan > b.maxRetargetTimespan {
        adjustedTimespan = b.maxRetargetTimespan
    }

    // Calculate new target difficulty as:
    //  currentDifficulty  (adjustedTimespan / targetTimespan)
    // The result uses integer division which means it will be slightly
    // rounded down.  Bitcoind also uses integer division to calculate this
    // result.
    oldTarget := CompactToBig(lastNode.bits)
    newTarget := new(big.Int).Mul(oldTarget, big.NewInt(adjustedTimespan))
    targetTimeSpan := int64(b.chainParams.TargetTimespan / time.Second)
    newTarget.Div(newTarget, big.NewInt(targetTimeSpan))                      (5)

    // Limit new value to the proof of work limit.
    if newTarget.Cmp(b.chainParams.PowLimit) > 0 {
        newTarget.Set(b.chainParams.PowLimit)                                 (6)
    }

    // Log new target difficulty and return it.  The new target logging is
    // intentionally converting the bits back to a number instead of using
    // newTarget since conversion to the compact representation loses
    // precision.
    newTargetBits := BigToCompact(newTarget)                                  (7)
    ......

    return newTargetBits, nil
}

```
其主要步骤如下:

 如果待加入区块的高度在一个调整周期(2016个区块, 平均14天一次)内，则期望的难度值就是父区块的难度值，即不需要调整难度值，如代码(1)、(2)处所示;
 如果待加入区块的高度是2016的整数倍，则需要进行难度调整，首先找到上一次调整周期的起始区块，它的高度也是2016的整数倍，如代码(3)处所示;
 代码(4)处计算上一次调整周期内经过的时间差，即周期内最后一个区块与起始区块的时间戳的差值，其值的有效范围为3.5天到56天，如果限过这一范围，则取其上限或下限;
 代码(5)处按如下公式计算新的难度值:

![image.png](https://upload-images.jianshu.io/upload_images/422094-f0c86b124f688ad3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中targetTimespan是14天，当上一次调整周期(即currentTimespan)超过14天时，说明“出块”速度变慢，要降低难度值；当currentTimespan小于14天时，说明“出块”速度过快，要增加难度值。可以看出，困难调整算法就是为了稳定“出块”速度;

 如果调整后的目标难度值大于设定的上限，则将其值直接设为该限，即2^224 - 1。请注意，难度值越大，说明“出块”的难度越小，这里的上限实际上是设定了“出块”的最低难度;
 最后调用BigToCompact()将目标难度值编码为难度Bits，如代码(7)处所示;

Bitcoin的难度调整算法很简单, 就是将前2016块的时间加起来与理论值作比较, 再求出之后的值, 简单明了.
### DCR
我们再来看看DCR难度调整的实现:
```
// 通过prevNode来计算下一个块的难度, curNode是父块, 计算的是下一块要满足的难度
// newBlockTime 是当前块的 header.Timestamp

// calcNextRequiredDifficulty calculates the required difficulty for the block
// after the passed previous block node based on the difficulty retarget rules.
// This function differs from the exported CalcNextRequiredDifficulty in that
// the exported version uses the current best chain as the previous block node
// while this function accepts any block node.
func (b BlockChain) calcNextRequiredDifficulty(curNode blockNode, newBlockTime time.Time) (uint32, error) {
   // Get the old difficulty; if we aren't at a block height where it changes,
   // just return this.
   oldDiff := curNode.bits
   oldDiffBig := CompactToBig(curNode.bits)

   // 不在难度调整区间, 则直接返回旧的难度, WorkDiffWindowSize = 144
   // DCR每114块调整一次难度, 约半天的时间(一天有 24  12 = 288块)
   // We're not at a retarget point, return the oldDiff.
   if (curNode.height+1)%b.chainParams.WorkDiffWindowSize != 0 {
      // For networks that support it, allow special reduction of the
      // required difficulty once too much time has elapsed without
      // mining a block.
      if b.chainParams.ReduceMinDifficulty {
         //...
      }
      return oldDiff, nil
   }

   // Declare some useful variables.
   RAFBig := big.NewInt(b.chainParams.RetargetAdjustmentFactor)
   nextDiffBigMin := CompactToBig(curNode.bits)
   nextDiffBigMin.Div(nextDiffBigMin, RAFBig)
   nextDiffBigMax := CompactToBig(curNode.bits)
   nextDiffBigMax.Mul(nextDiffBigMax, RAFBig)

   alpha := b.chainParams.WorkDiffAlpha

   // 
   // Number of nodes to traverse while calculating difficulty.
   nodesToTraverse := (b.chainParams.WorkDiffWindowSize 
      b.chainParams.WorkDiffWindows) // 144  20

   // Initialize bigInt slice for the percentage changes for each window period
   // above or below the target.
   windowChanges := make([]big.Int, b.chainParams.WorkDiffWindows)

   // Regress through all of the previous blocks and store the percent changes
   // per window period; use bigInts to emulate 64.32 bit fixed point.
   var olderTime, windowPeriod int64
   var weights uint64
   oldNode := curNode
   recentTime := curNode.timestamp

   for i := int64(0); ; i++ {
      // Store and reset after reaching the end of every window period.
      if i%b.chainParams.WorkDiffWindowSize == 0 &amp;&amp; i != 0 {
         // (1)
         olderTime = oldNode.timestamp
         timeDifference := recentTime - olderTime

         // Just assume we're at the target (no change) if we've
         // gone all the way back to the genesis block.
         if oldNode.height == 0 {
            timeDifference = int64(b.chainParams.TargetTimespan /
               time.Second)
         }

         timeDifBig := big.NewInt(timeDifference)
         timeDifBig.Lsh(timeDifBig, 32) // Add padding
         targetTemp := big.NewInt(int64(b.chainParams.TargetTimespan /
            time.Second))
         // (2) 计算windowAdjusted
         windowAdjusted := targetTemp.Div(timeDifBig, targetTemp)

         //  2
         // Weight it exponentially. Be aware that this could at some point
         // overflow if alpha or the number of blocks used is really large.
         windowAdjusted = windowAdjusted.Lsh(windowAdjusted,
            uint((b.chainParams.WorkDiffWindows-windowPeriod)alpha))
         // (3) 计算weights, 权重相加
         // Sum up all the different weights incrementally.
         weights += 1 << uint64((b.chainParams.WorkDiffWindows-windowPeriod)
            alpha)

         // Store it in the slice.
         windowChanges[windowPeriod] = windowAdjusted

         windowPeriod++

         recentTime = olderTime
      }

      if i == nodesToTraverse {
         break // Exit for loop when we hit the end.
      }

      // Get the previous node while staying at the genesis block as
      // needed.
      if oldNode.parent != nil {
         oldNode = oldNode.parent
      }
   }

   // Sum up the weighted window periods.
   weightedSum := big.NewInt(0)
   for i := int64(0); i < b.chainParams.WorkDiffWindows; i++ {
      weightedSum.Add(weightedSum, windowChanges[i])
   }

   // Divide by the sum of all weights.
   weightsBig := big.NewInt(int64(weights))
   weightedSumDiv := weightedSum.Div(weightedSum, weightsBig)

   // Multiply by the old diff.
   nextDiffBig := weightedSumDiv.Mul(weightedSumDiv, oldDiffBig)

   // Right shift to restore the original padding (restore non-fixed point).
   nextDiffBig = nextDiffBig.Rsh(nextDiffBig, 32)

   // Check to see if we're over the limits for the maximum allowable retarget;
   // if we are, return the maximum or minimum except in the case that oldDiff
   // is zero.
   if oldDiffBig.Cmp(bigZero) == 0 { // This should never really happen,
      nextDiffBig.Set(nextDiffBig) // but in case it does...
   } else if nextDiffBig.Cmp(bigZero) == 0 {
      nextDiffBig.Set(b.chainParams.PowLimit)
   } else if nextDiffBig.Cmp(nextDiffBigMax) == 1 {
      nextDiffBig.Set(nextDiffBigMax)
   } else if nextDiffBig.Cmp(nextDiffBigMin) == -1 {
      nextDiffBig.Set(nextDiffBigMin)
   }

   // Limit new value to the proof of work limit.
   if nextDiffBig.Cmp(b.chainParams.PowLimit) > 0 {
      nextDiffBig.Set(b.chainParams.PowLimit)
   }

   nextDiffBits := BigToCompact(nextDiffBig)
   return nextDiffBits, nil
}

```
代码是不是感觉比Bitcoin复杂多了? WorkDiffWindowSize? WorkDiffWindows? TargetTimespan?

 WorkDiffWindowSize = 144 每144块为一组
 WorkDiffWindows = 20 总共20组
 TargetTimespan = 144 块理论上所花费的时间 = 144460s

计算公式为:
[图片上传中...(image.png-5057e9-1560767440869-0)]

DCR不是简单的将之前块的时间相加, 它有了组和权重的概念, 最近的组权重越大, 使得难度调整更准确. 
假设我们现在有575块, 现在要入576块, 所以要计算576的难度. 按144块一组, 分成3组, 并从后往前标为 0, 1, 2, 3:

 432 434 ... 575 (0组)
 288 289 ... 431 (1组)
 144 145 ... 287 (2组)
 0 1 .... 143 (3组)

如何计算:
如代码(1) 每一组, 只选最后一个块来计算与前一组最后一块的时间差timeDifference. 如
现在我们计算第0组的 windowAdjusted, weights
```
TargetTimespan = 60  5  144 // 144 块理论上要多少秒
windowPeriod = 0 // 第0组
timeDifference0 = 块575-块431的时间差
windowAdjusted0 = timeDifference0/targetTimespan  2^(WorkDiffWindows-windowPeriod)
               = timeDifference0/targetTimespan  2^20
weights = 2^(WorkDiffWindows-windowPeriod)
        = 2^20

```
同理计算第1组:
```
timeDifference1 = 块431-块287的时间差
windowAdjusted1 = timeDifference1/targetTimespan  2^19
weights = 2^20 + 2^19

```
...
到最后:
```
所有windowAdjusted = [timeDifference0/targetTimespan  2^20, timeDifference1/targetTimespan  2^19, ...., timeDifference19/targetTimespan  2^1]
weights = 2^20 + 2^19 + .... + 2^1

```
最后计算next diff
```
weightedSum = sum(所有windowAdjusted)
nextDiffBig = oldDiffBig  weightedSum/weights

```
如果每个timeDifference都和理论值相匹配, 那最后的next diff是否和old diff一样呢?
肯定是的:
timeDifference0 == targetTemp
timeDifference1 == targetTemp
timeDifference2 ==  targetTemp
最后 weightedSum/weights = 1
可以得出,  最近组权重越大2^20, 最远的组, 权重最后变成了2^1, 所以DCR加大了最近块的时间权重, 比Bitcoin的算法更合理.
## workSum
难度值体现在 header中的Bits
blockNode{}有一个字段是workSum表示链上从最初始该结点的难度之和
work由header的Bits转换而成:
```
// CalcWork(blockHeader.Bits)
func CalcWork(bits uint32) big.Int {
   // Return a work value of zero if the passed difficulty bits represent
   // a negative number. Note this should not happen in practice with valid
   // blocks, but an invalid block could trigger it.
   difficultyNum := CompactToBig(bits)
   if difficultyNum.Sign() <= 0 {
      return big.NewInt(0)
   }

   // (1 << 256) / (difficultyNum + 1)
   denominator := new(big.Int).Add(difficultyNum, bigOne)
   return new(big.Int).Div(oneLsh256, denominator)
}

```
通过看代码, 得知
```
work = (1 << 256) / (difficultyNum + 1)

```
所以, work与difficultyNum是成反比例的, workSum越大表示难度越大.

